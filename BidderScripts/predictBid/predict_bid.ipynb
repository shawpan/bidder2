{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "import json\n",
    "import bidding_data\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidding_data.download_stats_file_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = 'wsbidder'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "output_path = 's3://{}/trainer_predict_bid/model_output'.format(bucket)\n",
    "model_dir = 's3://{}/trainer_predict_bid/model'.format(bucket)\n",
    "\n",
    "# train_instance_type = 'ml.c4.xlarge'\n",
    "train_instance_type = 'ml.p2.xlarge'\n",
    "train_instance_count = 1\n",
    "hyperparameters = {'epochs': 500, 'batch_size': 8, 'config_file': 'config.json'}\n",
    "inputs = {'train': 's3://wsbidder/trainer_predict_bid/data/train/',\n",
    "          'eval': 's3://wsbidder/trainer_predict_bid/data/eval/',\n",
    "          'test': 's3://wsbidder/trainer_predict_bid/data/eval/'}\n",
    "# inputs = {'train': '/opt/ml/input/data/train/',\n",
    "#           'eval': '/opt/ml/input/data/eval/',\n",
    "#           'test': '/opt/ml/input/data/eval/'}\n",
    "base_job_name = 'tf-bid-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='trainer.py',\n",
    "                       source_dir='.',\n",
    "                       output_path=output_path,\n",
    "                       model_dir=model_dir,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_instance_count=train_instance_count,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=get_execution_role(),\n",
    "#                        image_name='520713654638.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-tensorflow-scriptmode:1.12.0-gpu-py3',\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.14.0',\n",
    "                       py_version='py3',\n",
    "#                        distributions={'parameter_server': {'enabled': True}},\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# # Define objective\n",
    "# objective_metric_name = 'loss'\n",
    "# objective_type = 'Minimize'\n",
    "# metric_definitions = [{'Name': 'loss',\n",
    "#                        'Regex': 'loss = ([0-9\\\\.]+)'}]\n",
    "# # Define hyperparameter ranges\n",
    "# hyperparameter_ranges = {\n",
    "#                             'learning_rate': ContinuousParameter(1e-6, 1e-4)\n",
    "# #                             'dropout_rate': ContinuousParameter(0.0, 0.5)\n",
    "#                         }  \n",
    "# # hyperparameter_ranges = {\n",
    "# #                             'learning_rate': ContinuousParameter(0.0000001, 0.0001),\n",
    "# #                             'dropout_rate': ContinuousParameter(0.0, 0.9),\n",
    "# #                             'batch_size': IntegerParameter(512, 4096)\n",
    "# #                         }  \n",
    "# # Initialise Sagemaker's hyperparametertuner\n",
    "# tuner = HyperparameterTuner(estimator,\n",
    "#                             objective_metric_name,\n",
    "#                             hyperparameter_ranges,\n",
    "#                             metric_definitions,\n",
    "#                             max_jobs=4,\n",
    "#                             max_parallel_jobs=2,\n",
    "#                             objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "for obj in s3.Bucket(bucket).objects.filter(Prefix='trainer_predict_bid/model/'):\n",
    "    s3.Object(bucket,obj.key).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.c5.large',\n",
    "#     endpoint_name='BidPredictionProductionEndpoint',\n",
    "#     update_endpoint=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "# model_data = 's3://wsbidder/trainer_predict_imp/model_output/sagemaker-tensorflow-190731-1106-015-063c2327/output/model.tar.gz'\n",
    "\n",
    "# model = Model(\n",
    "#     model_data=model_data, \n",
    "#     role=get_execution_role()\n",
    "# )\n",
    "# model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.c5.large',\n",
    "#     endpoint_name='BidPredictionProductionEndpoint',\n",
    "#     update_endpoint=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 07:46:50 Starting - Starting the training job...\n",
      "2019-12-05 07:46:51 Starting - Launching requested ML instances......\n",
      "2019-12-05 07:48:16 Starting - Preparing the instances for training.........\n",
      "2019-12-05 07:49:25 Downloading - Downloading input data...\n",
      "2019-12-05 07:49:52 Training - Downloading the training image...\n",
      "2019-12-05 07:50:50 Training - Training image download completed. Training in progress..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW1205 07:50:56.840049 140360579442432 deprecation_wrapper.py:119] From trainer.py:261: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:56.840863 140360579442432 deprecation_wrapper.py:119] From trainer.py:238: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:56.841053 140360579442432 deprecation_wrapper.py:119] From trainer.py:238: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.363626 140360579442432 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34mThe TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34mFor more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34mIf you depend on functionality not listed there, please file an issue.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.363998 140360579442432 deprecation_wrapper.py:119] From trainer.py:172: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.578764 140360579442432 estimator.py:209] Using config: {'_model_dir': 's3://wsbidder/trainer_predict_bid/model/1575532256/', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7d8f0dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.580152 140360579442432 estimator.py:209] Using config: {'_model_dir': 's3://wsbidder/trainer_predict_bid/model/1575532256/', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7d8f0d780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.582219 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:806: NumericColumn._parse_example_spec (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.582428 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:806: EmbeddingColumn._parse_example_spec (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.582581 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3014: HashedCategoricalColumn._parse_example_spec (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.583201 140360579442432 estimator_training.py:186] Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.583458 140360579442432 training.py:612] Running training and evaluation locally (non-distributed).\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.583833 140360579442432 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.669830 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.709873 140360579442432 deprecation_wrapper.py:119] From /opt/ml/code/bidding_data.py:151: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.758541 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.762636 140360579442432 deprecation.py:323] From /opt/ml/code/bidding_data.py:282: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.789435 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:50:58.789656 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.789891 140360579442432 deprecation_wrapper.py:119] From trainer.py:184: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1205 07:50:58.799141 140360579442432 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mW1205 07:50:59.089185 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3038: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mW1205 07:50:59.596193 140360579442432 deprecation.py:323] From /opt/ml/code/bidding_data.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1205 07:51:03.339416 140360579442432 deprecation.py:323] From /opt/ml/code/losses.py:11: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\u001b[0m\n",
      "\u001b[34mW1205 07:51:03.342162 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThe TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\u001b[0m\n",
      "\u001b[34mI1205 07:51:06.729605 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:06.729808 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:06.731453 140360579442432 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mI1205 07:51:09.032167 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m2019-12-05 07:51:10.220969: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mI1205 07:51:12.073442 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:12.148655 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:16.259820 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 0 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mI1205 07:51:21.902472 140360579442432 basic_session_run_hooks.py:262] loss = 0.20793341, step = 0\u001b[0m\n",
      "\u001b[34mI1205 07:51:26.510370 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 100 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mI1205 07:51:28.376795 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:28.377083 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:32.018687 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mW1205 07:51:32.096465 140360579442432 deprecation_wrapper.py:119] From trainer.py:110: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\u001b[0m\n",
      "\u001b[34mI1205 07:51:32.131763 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:32.155322 140360579442432 evaluation.py:255] Starting evaluation at 2019-12-05T07:51:32Z\u001b[0m\n",
      "\u001b[34mI1205 07:51:32.607636 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mW1205 07:51:32.610475 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34mI1205 07:51:32.692013 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-100\u001b[0m\n",
      "\u001b[34mI1205 07:51:33.283717 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:33.343148 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.014923 140360579442432 evaluation.py:167] Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.198432 140360579442432 evaluation.py:167] Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.391158 140360579442432 evaluation.py:167] Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.583083 140360579442432 evaluation.py:167] Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.770695 140360579442432 evaluation.py:167] Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:35.959831 140360579442432 evaluation.py:167] Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.173059 140360579442432 evaluation.py:167] Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.357722 140360579442432 evaluation.py:167] Evaluation [80/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.549083 140360579442432 evaluation.py:167] Evaluation [90/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.749518 140360579442432 evaluation.py:167] Evaluation [100/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.840669 140360579442432 evaluation.py:275] Finished evaluation at 2019-12-05-07:51:36\u001b[0m\n",
      "\u001b[34mI1205 07:51:36.840939 140360579442432 estimator.py:2039] Saving dict for global step 100: average_loss/targetbid = 0.3238835, global_step = 100, label/mean/targetbid = 0.57756186, loss = 0.3238835, loss_on_L = 0.2534288, loss_on_W = 0.070454724, prediction/mean/targetbid = 1.2334988\u001b[0m\n",
      "\u001b[34mI1205 07:51:37.717730 140360579442432 estimator.py:2099] Saving 'checkpoint_path' summary for global step 100: s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-100\u001b[0m\n",
      "\u001b[34mI1205 07:51:37.818145 140360579442432 exporter.py:288] Loading best metric from event files.\u001b[0m\n",
      "\u001b[34mW1205 07:51:37.905493 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/summary/summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse eager execution and: \u001b[0m\n",
      "\u001b[34m`tf.data.TFRecordDataset(path)`\u001b[0m\n",
      "\u001b[34mI1205 07:51:37.999313 140360579442432 basic_session_run_hooks.py:692] global_step/sec: 6.21217\u001b[0m\n",
      "\u001b[34mI1205 07:51:38.000437 140360579442432 basic_session_run_hooks.py:260] loss = 0.06422704, step = 100 (16.098 sec)\u001b[0m\n",
      "\u001b[34mI1205 07:51:40.823705 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 200 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mI1205 07:51:42.793074 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:42.793378 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:46.576534 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:46.688068 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:46.712258 140360579442432 evaluation.py:255] Starting evaluation at 2019-12-05T07:51:46Z\u001b[0m\n",
      "\u001b[34mI1205 07:51:47.166198 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mI1205 07:51:47.239670 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-200\u001b[0m\n",
      "\u001b[34mI1205 07:51:47.875128 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:47.938183 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:51:49.603814 140360579442432 evaluation.py:167] Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:49.793200 140360579442432 evaluation.py:167] Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:49.979138 140360579442432 evaluation.py:167] Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:50.158757 140360579442432 evaluation.py:167] Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:50.337729 140360579442432 evaluation.py:167] Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:50.524224 140360579442432 evaluation.py:167] Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:50.701544 140360579442432 evaluation.py:167] Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:50.894035 140360579442432 evaluation.py:167] Evaluation [80/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.089168 140360579442432 evaluation.py:167] Evaluation [90/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.298523 140360579442432 evaluation.py:167] Evaluation [100/100]\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.391266 140360579442432 evaluation.py:275] Finished evaluation at 2019-12-05-07:51:51\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.391544 140360579442432 estimator.py:2039] Saving dict for global step 200: average_loss/targetbid = 0.16611212, global_step = 200, label/mean/targetbid = 0.57756186, loss = 0.16611212, loss_on_L = 0.068280384, loss_on_W = 0.097831726, prediction/mean/targetbid = 1.7199188\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.496879 140360579442432 estimator.py:2099] Saving 'checkpoint_path' summary for global step 200: s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-200\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.600278 140360579442432 exporter.py:299] Performing best model export.\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.927325 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:51.927594 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.117503 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.117698 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mW1205 07:51:55.117928 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:95: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.118449 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.118564 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.118699 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.118816 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.118942 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mI1205 07:51:55.537412 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-200\u001b[0m\n",
      "\u001b[34mI1205 07:51:56.065085 140360579442432 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34mI1205 07:51:56.065270 140360579442432 builder_impl.py:456] No assets to write.\u001b[0m\n",
      "\u001b[34mI1205 07:51:57.392722 140360579442432 builder_impl.py:421] SavedModel written to: s3://wsbidder/trainer_predict_bid/model/1575532256/export/predict_bid/temp-b'1575532311'/saved_model.pb\u001b[0m\n",
      "\u001b[34mI1205 07:51:58.026465 140360579442432 basic_session_run_hooks.py:692] global_step/sec: 4.99322\u001b[0m\n",
      "\u001b[34mI1205 07:51:58.027580 140360579442432 basic_session_run_hooks.py:260] loss = 0.10086131, step = 200 (20.027 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mI1205 07:52:00.833875 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 300 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mI1205 07:52:04.190626 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:04.190906 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:07.766943 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:08.078670 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:08.102421 140360579442432 evaluation.py:255] Starting evaluation at 2019-12-05T07:52:08Z\u001b[0m\n",
      "\u001b[34mI1205 07:52:08.554992 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mI1205 07:52:08.655678 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-300\u001b[0m\n",
      "\u001b[34mI1205 07:52:09.296612 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:09.357831 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:11.036968 140360579442432 evaluation.py:167] Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:11.229891 140360579442432 evaluation.py:167] Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:11.450396 140360579442432 evaluation.py:167] Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:11.638293 140360579442432 evaluation.py:167] Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:11.825495 140360579442432 evaluation.py:167] Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.019356 140360579442432 evaluation.py:167] Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.203447 140360579442432 evaluation.py:167] Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.394043 140360579442432 evaluation.py:167] Evaluation [80/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.583634 140360579442432 evaluation.py:167] Evaluation [90/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.774379 140360579442432 evaluation.py:167] Evaluation [100/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.866405 140360579442432 evaluation.py:275] Finished evaluation at 2019-12-05-07:52:12\u001b[0m\n",
      "\u001b[34mI1205 07:52:12.866671 140360579442432 estimator.py:2039] Saving dict for global step 300: average_loss/targetbid = 0.15527347, global_step = 300, label/mean/targetbid = 0.57756186, loss = 0.15527347, loss_on_L = 0.050439425, loss_on_W = 0.10483406, prediction/mean/targetbid = 1.8007445\u001b[0m\n",
      "\u001b[34mI1205 07:52:13.045341 140360579442432 estimator.py:2099] Saving 'checkpoint_path' summary for global step 300: s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-300\u001b[0m\n",
      "\u001b[34mI1205 07:52:13.166869 140360579442432 exporter.py:299] Performing best model export.\u001b[0m\n",
      "\u001b[34mI1205 07:52:13.313655 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:13.313919 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.528882 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.529072 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.529620 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.529736 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.529869 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.529993 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.530109 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:16.931384 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-300\u001b[0m\n",
      "\u001b[34mI1205 07:52:17.619486 140360579442432 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34mI1205 07:52:17.619692 140360579442432 builder_impl.py:456] No assets to write.\u001b[0m\n",
      "\u001b[34mI1205 07:52:18.961570 140360579442432 builder_impl.py:421] SavedModel written to: s3://wsbidder/trainer_predict_bid/model/1575532256/export/predict_bid/temp-b'1575532333'/saved_model.pb\u001b[0m\n",
      "\u001b[34mI1205 07:52:19.613092 140360579442432 basic_session_run_hooks.py:692] global_step/sec: 4.6325\u001b[0m\n",
      "\u001b[34mI1205 07:52:19.614203 140360579442432 basic_session_run_hooks.py:260] loss = 0.2444385, step = 300 (21.587 sec)\u001b[0m\n",
      "\u001b[34mI1205 07:52:22.457692 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 400 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mI1205 07:52:24.234005 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:24.234315 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:27.811577 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:27.924889 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:27.948982 140360579442432 evaluation.py:255] Starting evaluation at 2019-12-05T07:52:27Z\u001b[0m\n",
      "\u001b[34mI1205 07:52:28.404404 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mI1205 07:52:28.488519 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-400\u001b[0m\n",
      "\u001b[34mI1205 07:52:29.101261 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:29.178557 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:30.866656 140360579442432 evaluation.py:167] Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.044449 140360579442432 evaluation.py:167] Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.225285 140360579442432 evaluation.py:167] Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.406189 140360579442432 evaluation.py:167] Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.613437 140360579442432 evaluation.py:167] Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.796413 140360579442432 evaluation.py:167] Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:31.976090 140360579442432 evaluation.py:167] Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.170679 140360579442432 evaluation.py:167] Evaluation [80/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.350381 140360579442432 evaluation.py:167] Evaluation [90/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.533512 140360579442432 evaluation.py:167] Evaluation [100/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.636883 140360579442432 evaluation.py:275] Finished evaluation at 2019-12-05-07:52:32\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.637161 140360579442432 estimator.py:2039] Saving dict for global step 400: average_loss/targetbid = 0.15695196, global_step = 400, label/mean/targetbid = 0.57756186, loss = 0.15695196, loss_on_L = 0.064190656, loss_on_W = 0.092761256, prediction/mean/targetbid = 1.7049631\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.758147 140360579442432 estimator.py:2099] Saving 'checkpoint_path' summary for global step 400: s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-400\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.948915 140360579442432 basic_session_run_hooks.py:692] global_step/sec: 7.4986\u001b[0m\n",
      "\u001b[34mI1205 07:52:32.949947 140360579442432 basic_session_run_hooks.py:260] loss = 0.112538025, step = 400 (13.336 sec)\u001b[0m\n",
      "\u001b[34mI1205 07:52:35.786107 140360579442432 basic_session_run_hooks.py:606] Saving checkpoints for 500 into s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt.\u001b[0m\n",
      "\u001b[34mW1205 07:52:36.663548 140360579442432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34mI1205 07:52:37.931078 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:37.931376 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:41.688497 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:41.809906 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:41.833333 140360579442432 evaluation.py:255] Starting evaluation at 2019-12-05T07:52:41Z\u001b[0m\n",
      "\u001b[34mI1205 07:52:42.285467 140360579442432 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mI1205 07:52:42.401089 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-500\u001b[0m\n",
      "\u001b[34mI1205 07:52:43.011549 140360579442432 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:43.076007 140360579442432 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI1205 07:52:44.786404 140360579442432 evaluation.py:167] Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:44.975054 140360579442432 evaluation.py:167] Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:45.157449 140360579442432 evaluation.py:167] Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:45.346549 140360579442432 evaluation.py:167] Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:45.534259 140360579442432 evaluation.py:167] Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:45.720781 140360579442432 evaluation.py:167] Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:45.912085 140360579442432 evaluation.py:167] Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.098650 140360579442432 evaluation.py:167] Evaluation [80/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.286868 140360579442432 evaluation.py:167] Evaluation [90/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.474026 140360579442432 evaluation.py:167] Evaluation [100/100]\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.567183 140360579442432 evaluation.py:275] Finished evaluation at 2019-12-05-07:52:46\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.567448 140360579442432 estimator.py:2039] Saving dict for global step 500: average_loss/targetbid = 0.1505625, global_step = 500, label/mean/targetbid = 0.57756186, loss = 0.1505625, loss_on_L = 0.057841163, loss_on_W = 0.09272136, prediction/mean/targetbid = 1.7163854\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.735220 140360579442432 estimator.py:2099] Saving 'checkpoint_path' summary for global step 500: s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-500\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.850565 140360579442432 exporter.py:299] Performing best model export.\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.992963 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:46.993243 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.173889 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.174092 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.174644 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.174771 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.174894 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.175019 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.175129 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:50.823084 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-500\u001b[0m\n",
      "\u001b[34mI1205 07:52:51.324414 140360579442432 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34mI1205 07:52:51.324603 140360579442432 builder_impl.py:456] No assets to write.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mI1205 07:52:53.109057 140360579442432 builder_impl.py:421] SavedModel written to: s3://wsbidder/trainer_predict_bid/model/1575532256/export/predict_bid/temp-b'1575532366'/saved_model.pb\u001b[0m\n",
      "\u001b[34mI1205 07:52:54.599410 140360579442432 estimator.py:368] Loss for final step: 0.34212524.\u001b[0m\n",
      "\u001b[34mFinished training\u001b[0m\n",
      "\u001b[34mI1205 07:52:54.773147 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:54.773410 140360579442432 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.642431 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.642635 140360579442432 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.643187 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.643320 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.643444 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.643545 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:57.643682 140360579442432 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mI1205 07:52:58.116976 140360579442432 saver.py:1286] Restoring parameters from s3://wsbidder/trainer_predict_bid/model/1575532256/model.ckpt-500\u001b[0m\n",
      "\u001b[34mI1205 07:52:58.624937 140360579442432 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34mI1205 07:52:58.625118 140360579442432 builder_impl.py:456] No assets to write.\u001b[0m\n",
      "\u001b[34mI1205 07:52:59.130548 140360579442432 builder_impl.py:421] SavedModel written to: /opt/ml/model/temp-b'1575532374'/saved_model.pb\u001b[0m\n",
      "\n",
      "2019-12-05 07:53:08 Uploading - Uploading generated training model\n",
      "2019-12-05 07:53:08 Completed - Training job completed\n",
      "Training seconds: 223\n",
      "Billable seconds: 223\n",
      "CPU times: user 896 ms, sys: 39.7 ms, total: 935 ms\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.c5.large',\n",
    "#     endpoint_name='BidPredictionProductionEndpoint'\n",
    "# #     update_endpoint=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
